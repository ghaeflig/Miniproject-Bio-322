{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to prepare the data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "3029"
      ],
      "text/latex": [
       "3029"
      ],
      "text/markdown": [
       "3029"
      ],
      "text/plain": [
       "[1] 3029"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data <- read.csv(file.path(\"..\", \"data\", \"training_data.csv\"))\n",
    "data<-data[,-which(names(data) %in% c(\"SWEETORSOUR\"))] \n",
    "data$Intensity<-as.numeric(as.factor(data$Intensity))\n",
    "var0<-which(apply(data, 2, var) == 0)                              #this can be reused when preparing future test data\n",
    "data<-data[ ,-var0] \n",
    "\n",
    "set.seed(199)\n",
    "idx.train <- sample(nrow(data), nrow(data)*2/3)                    #separate data into training and validation set (using the validation set approach)\n",
    "data.train <- data[idx.train,]\n",
    "datax.train<-data.train[,-which(names(data.train) %in% c(\"VALENCE.PLEASANTNESS\"))]  #separate between the response and the predictors\n",
    "datay.train<-data.train$VALENCE.PLEASANTNESS\n",
    "\n",
    "data.test <- data[-idx.train,]\n",
    "datax.test<-data.test[,-which(names(data.test) %in% c(\"VALENCE.PLEASANTNESS\"))]\n",
    "datay.test<-as.matrix(data.test$VALENCE.PLEASANTNESS)\n",
    "#using more data samples\n",
    "\n",
    "#verifiy if some new cols now have var 0\n",
    "train.var<-(apply(datax.train, 2, var) != 0)\n",
    "test.var<-(apply(datax.test,2,var)!=0)\n",
    "\n",
    "datax.train<-datax.train[,which(test.var&train.var)] #take the same columns for both sets and only when both have var!=0\n",
    "datax.test<-datax.test[,which(test.var&train.var)]\n",
    "ncol(data.test)\n",
    "\n",
    "datax.train<-as.matrix(datax.train)       #transform into matrix for neuron networks\n",
    "datax.test<-as.matrix(datax.test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define the model of neural network with the possibility to add regularizer or callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(keras)\n",
    "use_condaenv(\"r-tensorflow\")\n",
    "\n",
    "#baseline model\n",
    "fitnn<-function(datax.train,datay.train,datax.test,datay.test,callback=NULL, kernel_regularizer=NULL, print=FALSE,printresult=TRUE){ #If we want to have more detail of the process we can print plot (print=True or printresult to show train and test error)\n",
    "    use_session_with_seed(24)                              #enables to have reproducibility\n",
    "    set.seed(24)\n",
    "    model <- keras_model_sequential() %>% \n",
    "       layer_dense(units=64, activation=\"relu\",kernel_regularizer=kernel_regularizer, input_shape=ncol(datax.train)) %>% \n",
    "       layer_dense(units=64, activation=\"relu\", kernel_regularizer=kernel_regularizer) %>% \n",
    "       layer_dropout(rate=0.6)%>%\n",
    "       layer_dense(units=32, activation = \"relu\",kernel_regularizer=kernel_regularizer) %>% \n",
    "       layer_dropout(rate=0.3) %>%                              #dropout layers prevent overfitting to the model\n",
    "       layer_dense(units=1, activation=\"linear\",kernel_regularizer=kernel_regularizer)\n",
    "\n",
    "    model %>% compile(\n",
    "       loss = \"mse\",\n",
    "       optimizer =  \"adam\", #this tunes the learning rate\n",
    "     )\n",
    "    if(print)model %>% summary()\n",
    "    history<-model %>% fit(datax.train, \n",
    "                           datay.train,\n",
    "                           epochs=100,          #try to keep the training RMSE over the validation and epochs stop before 100 if we use a callback\n",
    "                           callback=callback,\n",
    "                           verbose = 0,\n",
    "                           batch_size =100,      #reducing batch_size reduces the RMSE (but increases computation time)\n",
    "                           validation_split = 0.2)\n",
    "    scores = model %>% evaluate(datax.train, datay.train, verbose = 0)\n",
    "    if(print) print(scores)\n",
    "    \n",
    "    #use the model\n",
    "    \n",
    "    ypred <- model %>% predict(datax.train)\n",
    "    ypred.test<- model %>% predict(datax.test)\n",
    "    \n",
    "    #estimate training and test error\n",
    "    \n",
    "    training_RMSE<-sqrt(mean(ypred-datay.train)^2)\n",
    "    test_RMSE<-sqrt(mean(ypred.test-datay.test)^2)\n",
    "    if(printresult){\n",
    "        print(paste0(\"Training RMSE:\", training_RMSE))\n",
    "        print(paste0(\" Test RMSE:\", test_RMSE))\n",
    "    }\n",
    "    \n",
    "    if(print) show(plot(history))\n",
    "    \n",
    "    return (test_RMSE) #useful for cross-validation\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the neuron networks have some intrinsinc variability, we will compute an estimate of the test error by 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define cross-validation function\n",
    "\n",
    "library(tidymodels)\n",
    "\n",
    "validation_data <- vfold_cv(data, v = 10) # create the 10 folds\n",
    "\n",
    "nn_fit_and_evaluate <- function(fold,callbacknn,kernel_regularizernn) {\n",
    "    #extract and prepare data\n",
    "    trainingx<-as.matrix(analysis(fold)[,-which(names(data.test) %in% c(\"VALENCE.PLEASANTNESS\"))]) #analysis(fold) return the training data for the fold, we separate them into x and y to meet the function requirement\n",
    "    trainingy<-as.matrix(analysis(fold)$VALENCE.PLEASANTNESS)\n",
    "    validation_setx <- as.matrix(assessment(fold)[,-which(names(data.test) %in% c(\"VALENCE.PLEASANTNESS\"))]) # the function `assessment` extracts the validation set from the fold\n",
    "    validation_sety<-as.matrix(assessment(fold)$VALENCE.PLEASANTNESS)\n",
    "    \n",
    "    #fit model\n",
    "    fitnn(datax.train=trainingx,datay.train=trainingy,validation_setx,validation_sety,printresult=FALSE,callback=callbacknn, kernel_regularizer=kernel_regularizernn) # the function `analysis` extracts the training set from the fold (marked blue in the slides)\n",
    "}\n",
    "\n",
    "#estimate test error on 10 folds and return the mean\n",
    "cross_validation_error<-function(validation_data,callbacknn=NULL,kernel_regularizernn=NULL){\n",
    "    mean(sapply(validation_data$splits, nn_fit_and_evaluate,callbacknn,kernel_regularizernn))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can compute the mean RMSE while testing with early stopping, L1 and L2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Simple model\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "19.7970471001079"
      ],
      "text/latex": [
       "19.7970471001079"
      ],
      "text/markdown": [
       "19.7970471001079"
      ],
      "text/plain": [
       "[1] 19.79705"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"callback\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "16.5999273312655"
      ],
      "text/latex": [
       "16.5999273312655"
      ],
      "text/markdown": [
       "16.5999273312655"
      ],
      "text/plain": [
       "[1] 16.59993"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"regularizer l1\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "18.7886602436273"
      ],
      "text/latex": [
       "18.7886602436273"
      ],
      "text/markdown": [
       "18.7886602436273"
      ],
      "text/plain": [
       "[1] 18.78866"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"regularizer l2\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "19.6381766597318"
      ],
      "text/latex": [
       "19.6381766597318"
      ],
      "text/markdown": [
       "19.6381766597318"
      ],
      "text/plain": [
       "[1] 19.63818"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"callback and regularizer l1\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n",
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "17.9532821331705"
      ],
      "text/latex": [
       "17.9532821331705"
      ],
      "text/markdown": [
       "17.9532821331705"
      ],
      "text/plain": [
       "[1] 17.95328"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#simple\n",
    "print(\"Simple model\")\n",
    "cross_validation_error(validation_data)\n",
    "\n",
    "#and now using an early stopping\n",
    "print(\"callback\")\n",
    "cross_validation_error(validation_data,callback=callback_early_stopping(monitor = \"val_loss\", patience = 10))#the results are clearly better with early stopping\n",
    "\n",
    "#Now try with kernel regularizer l1\n",
    "print(\"regularizer l1\")\n",
    "cross_validation_error(validation_data,kernel_regularizer=\"l1\")\n",
    "\n",
    "#And with kernel regularizer l2\n",
    "print(\"regularizer l2\")\n",
    "cross_validation_error(validation_data, kernel_regularizer=regularizer_l2(l = .1))\n",
    "\n",
    "#callback and regularizer\n",
    "print(\"callback and regularizer l1\")\n",
    "cross_validation_error(validation_data,callback=callback_early_stopping(monitor = \"val_loss\", patience = 10),kernel_regularizer=\"l1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We created the model based in the whole data with the regularization and callback that were determined by cross-validation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Set session seed to 24 (disabled GPU, CPU parallelism)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Layer (type)                        Output Shape                    Param #     \n",
      "================================================================================\n",
      "dense_3 (Dense)                     (None, 64)                      193856      \n",
      "________________________________________________________________________________\n",
      "dense_2 (Dense)                     (None, 64)                      4160        \n",
      "________________________________________________________________________________\n",
      "dropout_1 (Dropout)                 (None, 64)                      0           \n",
      "________________________________________________________________________________\n",
      "dense_1 (Dense)                     (None, 32)                      2080        \n",
      "________________________________________________________________________________\n",
      "dropout (Dropout)                   (None, 32)                      0           \n",
      "________________________________________________________________________________\n",
      "dense (Dense)                       (None, 1)                       33          \n",
      "================================================================================\n",
      "Total params: 200,129\n",
      "Trainable params: 200,129\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "set.seed(24)\n",
    "use_session_with_seed(24)\n",
    "\n",
    "#take the whole data set to have more information\n",
    "datax<-as.matrix(data[,-which(names(data) %in% c(\"VALENCE.PLEASANTNESS\"))])\n",
    "datay<-data$VALENCE.PLEASANTNESS\n",
    "\n",
    "#use the model defined previously\n",
    "model_tot <- keras_model_sequential() %>% \n",
    "   layer_dense(units=64, activation=\"relu\", input_shape=ncol(datax),kernel_regularizer=\"l1\") %>% \n",
    "   layer_dense(units=64, activation=\"relu\",kernel_regularizer=\"l1\") %>% \n",
    "   layer_dropout(rate=0.6)%>%\n",
    "   layer_dense(units=32, activation = \"relu\",kernel_regularizer=\"l1\") %>% \n",
    "   layer_dropout(rate=0.3) %>%                              #dropout layers prevent overfitting to the model\n",
    "   layer_dense(units=1, activation=\"linear\")\n",
    "\n",
    "\n",
    "model_tot %>% compile(\n",
    "   loss = \"mse\",\n",
    "   optimizer =  \"adam\", \n",
    ")\n",
    "\n",
    "model_tot %>% summary()\n",
    "history<-model_tot %>% fit(datax, \n",
    "                       datay,\n",
    "                       epochs=30,\n",
    "                       callback=callback_early_stopping(monitor = \"val_loss\", patience = 10), #we obtained good results with early stopping\n",
    "                       verbose = 0,\n",
    "                       batch_size =100,     \n",
    "                       validation_split = 0.2)\n",
    "scores = model_tot %>% evaluate(datax, datay, verbose = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We achieved relatively good results but the kaggle submission was not satisfying so we decided to further investigate tree methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
